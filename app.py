import streamlit as st
import plotly.graph_objects as go
import json
import anthropic
from io import BytesIO
import base64

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="WAIC AIæ½œåŠ›ç”»åƒç”Ÿæˆå™¨", 
    page_icon="ğŸ¤–",
    layout="wide"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-title {
        text-align: center;
        color: #1f77b4;
        font-size: 2.5rem;
        margin-bottom: 2rem;
        padding: 1rem;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    .golden-sentence {
        text-align: center;
        font-size: 1.5rem;
        color: #ff6b6b;
        font-weight: bold;
        padding: 1rem;
        background-color: #fff3cd;
        border-radius: 10px;
        margin: 1rem 0;
    }
    
    .analysis-box {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def create_radar_chart(scores, user_name):
    """åˆ›å»ºé›·è¾¾å›¾"""
    categories = ['åˆ›æ–°æŒ‡æ•°', 'åä½œæ½œåŠ›', 'é¢†å¯¼ç‰¹è´¨', 'æŠ€æœ¯æ•æ„Ÿåº¦']
    values = [
        scores['innovation'],
        scores['collaboration'], 
        scores['leadership'],
        scores['tech_acumen']
    ]
    
    # é—­åˆé›·è¾¾å›¾
    values_closed = values + [values[0]]
    categories_closed = categories + [categories[0]]
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=values_closed,
        theta=categories_closed,
        fill='toself',
        fillcolor='rgba(31, 119, 180, 0.3)',
        line=dict(color='rgba(31, 119, 180, 1)', width=3),
        marker=dict(size=8, color='rgba(31, 119, 180, 1)'),
        name=f'{user_name}çš„AIæ½œåŠ›ç”»åƒ'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100],
                tickfont=dict(size=12),
                gridcolor='rgba(0,0,0,0.1)'
            ),
            angularaxis=dict(
                tickfont=dict(size=14, color='#2c3e50'),
                gridcolor='rgba(0,0,0,0.1)'
            )
        ),
        showlegend=True,
        title=dict(
            text=f"ğŸ¯ {user_name} çš„ AI æ½œåŠ›é›·è¾¾å›¾",
            x=0.5,
            font=dict(size=20, color='#2c3e50')
        ),
        font=dict(family="Arial, sans-serif"),
        width=600,
        height=500,
        margin=dict(t=80, b=40, l=40, r=40)
    )
    
    return fig

def call_claude_api(user_inputs, user_name):
    """è°ƒç”¨Claude APIè¿›è¡Œåˆ†æ"""
    try:
        # è·å–APIå¯†é’¥
        api_key = st.secrets.get("CLAUDE_API_KEY", "")
        if not api_key:
            st.error("âŒ APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
            return None
            
        client = anthropic.Anthropic(api_key=api_key)
        
        # æ„å»ºåˆ†æprompt
        system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ€æœ¯æ‹›è˜å®˜å’ŒèŒä¸šå‘å±•é¡¾é—®ï¼Œå…·æœ‰ä¸°å¯Œçš„äººæ‰è¯„ä¼°ç»éªŒã€‚
        è¯·åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œä»å››ä¸ªç»´åº¦è¿›è¡Œä¸“ä¸šåˆ†æï¼šåˆ›æ–°æŒ‡æ•°ã€åä½œæ½œåŠ›ã€é¢†å¯¼ç‰¹è´¨ã€æŠ€æœ¯æ•æ„Ÿåº¦ã€‚

        è¯„åˆ†æ ‡å‡†ï¼š
        - åˆ›æ–°æŒ‡æ•°(innovation)ï¼šåŸåˆ›æ€ç»´ã€é—®é¢˜è§£å†³èƒ½åŠ›ã€åˆ›æ„å®ç°
        - åä½œæ½œåŠ›(collaboration)ï¼šå›¢é˜Ÿåˆä½œã€æ²Ÿé€šèƒ½åŠ›ã€é›†ä½“æ„è¯†  
        - é¢†å¯¼ç‰¹è´¨(leadership)ï¼šå†³ç­–èƒ½åŠ›ã€è´£ä»»æ‹…å½“ã€å½±å“åŠ›
        - æŠ€æœ¯æ•æ„Ÿåº¦(tech_acumen)ï¼šæŠ€æœ¯ç†è§£ã€å­¦ä¹ èƒ½åŠ›ã€å‰ç»æ€§

        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼š
        {
          "scores": {
            "innovation": <1-100ä¹‹é—´çš„æ•´æ•°>,
            "collaboration": <1-100ä¹‹é—´çš„æ•´æ•°>,
            "leadership": <1-100ä¹‹é—´çš„æ•´æ•°>,  
            "tech_acumen": <1-100ä¹‹é—´çš„æ•´æ•°>
          },
          "analysis": "<çº¦100-150å­—çš„ç»¼åˆåˆ†æï¼Œè¯­è¨€ç§¯æé¼“åŠ±ï¼Œçªå‡ºé—ªå…‰ç‚¹>",
          "golden_sentence": "<ä¸€å¥ç²¾ç‚¼çš„ä¸“å±è¯„è¯­ï¼Œä½œä¸ºç”¨æˆ·çš„AI Slogan>"
        }"""
        
        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·ä¿¡æ¯ï¼š

        ç”¨æˆ·æ˜µç§°ï¼š{user_name}

        åˆ›æ–°æŒ‡æ•°ç›¸å…³ä¿¡æ¯ï¼š
        {user_inputs['innovation']}

        åä½œæ½œåŠ›ç›¸å…³ä¿¡æ¯ï¼š
        {user_inputs['collaboration']}

        é¢†å¯¼ç‰¹è´¨ç›¸å…³ä¿¡æ¯ï¼š
        {user_inputs['leadership']}

        æŠ€æœ¯æ•æ„Ÿåº¦ç›¸å…³ä¿¡æ¯ï¼š
        {user_inputs['tech_acumen']}

        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯è¿›è¡Œä¸“ä¸šåˆ†æå¹¶æŒ‰JSONæ ¼å¼è¾“å‡ºã€‚"""
        
        message = client.messages.create(
            model="claude-3-haiku-20240307",  # ä½¿ç”¨Haikuæ¨¡å‹ï¼Œé€Ÿåº¦æ›´å¿«
            max_tokens=1000,
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        
        # è§£æè¿”å›ç»“æœ
        response_text = message.content[0].text.strip()
        
        # å°è¯•è§£æJSON
        try:
            result = json.loads(response_text)
            return result
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return result
            else:
                return None
                
    except Exception as e:
        st.error(f"âŒ APIè°ƒç”¨å‡ºç°é—®é¢˜ï¼š{str(e)}")
        return None

def convert_plotly_to_bytes(fig):
    """å°†Plotlyå›¾è¡¨è½¬æ¢ä¸ºå­—èŠ‚æµç”¨äºä¸‹è½½"""
    try:
        img_bytes = fig.to_image(format="png", width=800, height=600, scale=2)
        return img_bytes
    except Exception as e:
        st.error(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        return None

# ä¸»åº”ç”¨ç•Œé¢
def main():
    # ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-title">ğŸ¤– WAIC ç°åœºä¸“äº«ï¼šå…è´¹ AI æ½œåŠ›ç”»åƒç”Ÿæˆ</h1>', 
                unsafe_allow_html=True)
    
    # ç®€ä»‹
    st.markdown("""
    ### ğŸ¯ å‘ç°ä½ çš„AIæ—¶ä»£æ½œåŠ›
    é€šè¿‡AIæ·±åº¦åˆ†æï¼Œç”Ÿæˆä½ çš„ä¸“å±æ½œåŠ›é›·è¾¾å›¾ã€‚åªéœ€å‡ åˆ†é’Ÿï¼Œè·å¾—ä¸“ä¸šçš„èŒä¸šå‘å±•æ´å¯Ÿï¼
    """)
    
    # è·å–ç”¨æˆ·æ˜µç§°
    user_name = st.text_input("ğŸ‘¤ è¯·è¾“å…¥æ‚¨çš„æ˜µç§°", placeholder="ä¾‹å¦‚ï¼šå°ç‹ã€Alexã€æŠ€æœ¯è¾¾äºº...")
    
    if user_name:
        st.markdown(f"### ğŸ‘‹ Hi {user_name}ï¼Œè¯·å›ç­”ä»¥ä¸‹å››ä¸ªé—®é¢˜ï¼š")
        
        # åˆ›å»ºè¡¨å•
        with st.form("profile_form"):
            st.markdown("#### ğŸ“ è¯·è¯¦ç»†å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œè¿™å°†å¸®åŠ©AIæ›´å‡†ç¡®åœ°åˆ†æä½ çš„æ½œåŠ›ï¼š")
            
            # å››ä¸ªç»´åº¦çš„é—®é¢˜
            innovation_input = st.text_area(
                "ğŸ§  **åˆ›æ–°æŒ‡æ•°**ï¼šè¯·æè¿°ä¸€ä¸ªä½ è¿‘æœŸä¸»å¯¼æˆ–å‚ä¸çš„æœ€æœ‰åˆ›æ„çš„é¡¹ç›®æˆ–æƒ³æ³•ï¼Œä½ æ˜¯å¦‚ä½•è´¡çŒ®åŸåˆ›æ€è·¯çš„ï¼Ÿ",
                height=120,
                placeholder="è¯·è¯¦ç»†æè¿°ä½ çš„åˆ›æ–°ç»å†..."
            )
            
            collaboration_input = st.text_area(
                "ğŸ¤ **åä½œæ½œåŠ›**ï¼šè¯·æè¿°ä¸€æ¬¡é‡è¦çš„å›¢é˜Ÿåˆä½œç»å†ã€‚ä½ çš„è§’è‰²æ˜¯ä»€ä¹ˆï¼Ÿä½ å¦‚ä½•ä¿ƒè¿›æ²Ÿé€šå’Œå›¢é˜Ÿæ•ˆç‡ï¼Ÿ",
                height=120,
                placeholder="è¯·åˆ†äº«ä½ çš„å›¢é˜Ÿåä½œç»éªŒ..."
            )
            
            leadership_input = st.text_area(
                "ğŸ‘‘ **é¢†å¯¼ç‰¹è´¨**ï¼šæƒ³è±¡ä½ é¢†å¯¼çš„é¡¹ç›®ä¸¥é‡è½åï¼Œä½ ä¼šé‡‡å–å“ªä¸‰ä¸ªå…³é”®æ­¥éª¤æ¥æ‰­è½¬å±€é¢ï¼Ÿ",
                height=120,
                placeholder="è¯·æè¿°ä½ çš„é¢†å¯¼ç­–ç•¥..."
            )
            
            tech_acumen_input = st.text_area(
                "âš¡ **æŠ€æœ¯æ•æ„Ÿåº¦**ï¼šå“ªä¸€é¡¹æ–°å…´ AI æŠ€æœ¯ï¼ˆå¦‚ï¼šå¤šæ¨¡æ€ã€AI Agentã€ç”Ÿæˆå¼è§†é¢‘ï¼‰æœ€è®©ä½ æ„Ÿåˆ°å…´å¥‹ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿä½ è®¤ä¸ºå®ƒä¼šå¦‚ä½•æ”¹å˜ä½ æ‰€åœ¨çš„è¡Œä¸šï¼Ÿ",
                height=120,
                placeholder="è¯·åˆ†äº«ä½ å¯¹AIæŠ€æœ¯çš„è§è§£..."
            )
            
            # æäº¤æŒ‰é’®
            submitted = st.form_submit_button("ğŸš€ å¼€å§‹ç”Ÿæˆæˆ‘çš„ AI ç”»åƒ", use_container_width=True)
        
        # å¤„ç†è¡¨å•æäº¤
        if submitted:
            # éªŒè¯è¾“å…¥
            if not all([innovation_input.strip(), collaboration_input.strip(), 
                       leadership_input.strip(), tech_acumen_input.strip()]):
                st.warning("âš ï¸ è¯·å®Œæ•´å›ç­”æ‰€æœ‰å››ä¸ªé—®é¢˜ï¼Œè¿™æ ·AIæ‰èƒ½ç»™å‡ºæ›´å‡†ç¡®çš„åˆ†æå“¦ï¼")
                return
            
            # å‡†å¤‡ç”¨æˆ·è¾“å…¥æ•°æ®
            user_inputs = {
                'innovation': innovation_input,
                'collaboration': collaboration_input,
                'leadership': leadership_input,
                'tech_acumen': tech_acumen_input
            }
            
            # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            with st.spinner("âœ¨ AI å¤§æ¨¡å‹æ­£åœ¨ä¸ºæ‚¨æ·±åº¦åˆ†æï¼Œè¯·ç¨å€™..."):
                # è°ƒç”¨Claude API
                analysis_result = call_claude_api(user_inputs, user_name)
            
            if analysis_result:
                # æ˜¾ç¤ºç»“æœ
                st.markdown("---")
                st.header(f"ğŸ‰ Hey, {user_name}ï¼è¿™æ˜¯ä½ çš„ AI æ½œåŠ›ç”»åƒï¼š")
                
                # æ˜¾ç¤ºä¸“å±Slogan
                st.markdown(f"""
                <div class="golden-sentence">
                    âœ¨ {analysis_result['golden_sentence']} âœ¨
                </div>
                """, unsafe_allow_html=True)
                
                # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    # æ˜¾ç¤ºé›·è¾¾å›¾
                    fig = create_radar_chart(analysis_result['scores'], user_name)
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    # æ˜¾ç¤ºå„ç»´åº¦å¾—åˆ†
                    st.markdown("### ğŸ“Š è¯¦ç»†å¾—åˆ†")
                    
                    scores = analysis_result['scores']
                    st.metric("ğŸ§  åˆ›æ–°æŒ‡æ•°", f"{scores['innovation']}/100")
                    st.metric("ğŸ¤ åä½œæ½œåŠ›", f"{scores['collaboration']}/100") 
                    st.metric("ğŸ‘‘ é¢†å¯¼ç‰¹è´¨", f"{scores['leadership']}/100")
                    st.metric("âš¡ æŠ€æœ¯æ•æ„Ÿåº¦", f"{scores['tech_acumen']}/100")
                
                # æ˜¾ç¤ºç»¼åˆåˆ†æ
                st.markdown(f"""
                <div class="analysis-box">
                    <h3>ğŸ” AI ç»¼åˆåˆ†æ</h3>
                    <p style="font-size: 1.1rem; line-height: 1.6;">{analysis_result['analysis']}</p>
                </div>
                """, unsafe_allow_html=True)
                
                # ä¸‹è½½åŠŸèƒ½
                st.markdown("### ğŸ“¥ ä¿å­˜ä¸åˆ†äº«")
                
                # ç”Ÿæˆä¸‹è½½æŒ‰é’®
                img_bytes = convert_plotly_to_bytes(fig)
                if img_bytes:
                    st.download_button(
                        label="ğŸ“± ä¸‹è½½ç»“æœå›¾ï¼Œåˆ†äº«ä½ çš„ AI æ½œåŠ›",
                        data=img_bytes,
                        file_name=f"{user_name}_AIæ½œåŠ›ç”»åƒ_{st.session_state.get('timestamp', 'waic')}.png",
                        mime="image/png",
                        use_container_width=True
                    )
                
                # é‡æ–°åˆ†ææŒ‰é’®
                if st.button("ğŸ”„ é‡æ–°åˆ†æ", use_container_width=True):
                    st.experimental_rerun()
                    
            else:
                st.error("ğŸ˜… åˆ†æå‡ºäº†ä¸€ç‚¹å°é—®é¢˜ï¼Œè¯·æ‚¨è°ƒæ•´ä¸€ä¸‹è¾“å…¥å†…å®¹å†è¯•è¯•ã€‚ç¡®ä¿æ¯ä¸ªé—®é¢˜éƒ½æœ‰è¯¦ç»†çš„å›ç­”å“¦ï¼")

# ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.markdown("### ğŸª WAIC 2024")
    st.markdown("**ä¸–ç•Œäººå·¥æ™ºèƒ½å¤§ä¼šç°åœºä¸“äº«**")
    st.markdown("---")
    st.markdown("### ğŸ“‹ ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. è¾“å…¥æ‚¨çš„æ˜µç§°
    2. è¯¦ç»†å›ç­”å››ä¸ªç»´åº¦çš„é—®é¢˜
    3. ç­‰å¾…AIåˆ†æï¼ˆçº¦30ç§’ï¼‰
    4. è·å¾—ä¸“å±æ½œåŠ›é›·è¾¾å›¾
    5. ä¸‹è½½å›¾ç‰‡åˆ†äº«ç»™æœ‹å‹
    """)
    st.markdown("---")
    st.markdown("### ğŸ’¡ å°è´´å£«")
    st.markdown("""
    - å›ç­”è¶Šè¯¦ç»†ï¼Œåˆ†æè¶Šå‡†ç¡®
    - å¯ä»¥ç»“åˆå…·ä½“æ¡ˆä¾‹å’Œæ•°æ®
    - çœŸå®å›ç­”æ¯”å®Œç¾å›ç­”æ›´æœ‰ä»·å€¼
    """)

if __name__ == "__main__":
    main()

